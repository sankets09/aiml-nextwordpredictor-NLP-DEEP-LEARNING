{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Prediction Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the Libraries\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "\n",
    "# model = load_model('nextword1.h5')\n",
    "# tokenizer = pickle.load(open('tokenizer1.pkl', 'rb'))\n",
    "\n",
    "# def Predict_Next_Words(model, tokenizer, text):\n",
    "#     \"\"\"\n",
    "#         In this function we are using the tokenizer and models trained\n",
    "#         and we are creating the sequence of the text entered and then\n",
    "#         using our model to predict and return the the predicted word.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     for i in range(3):\n",
    "#         sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "#         sequence = np.array(sequence)\n",
    "        \n",
    "#         preds = model.predict_classes(sequence)\n",
    "# #         print(preds)\n",
    "#         predicted_word = \"\"\n",
    "        \n",
    "#         for key, value in tokenizer.word_index.items():\n",
    "#             if value == preds:\n",
    "#                 predicted_word = key\n",
    "#                 break\n",
    "        \n",
    "#         print(predicted_word)\n",
    "#         return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     We are testing our model and we will run the model\n",
    "#     until the user decides to stop the script.\n",
    "#     While the script is running we try and check if \n",
    "#     the prediction can be made on the text. If no\n",
    "#     prediction can be made we just continue.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# # text1 = \"at the dull\"\n",
    "# # text2 = \"collection of textile\"\n",
    "# # text3 = \"what a strenuous\"\n",
    "# # text4 = \"stop the script\"\n",
    "\n",
    "# while(True):\n",
    "\n",
    "#     text = input(\"Enter your line: \")\n",
    "    \n",
    "#     if text == \"stop the script\":\n",
    "#         print(\"Ending The Program.....\")\n",
    "#         break\n",
    "    \n",
    "#     else:\n",
    "#         try:\n",
    "#             text = text.split(\" \")\n",
    "#             text = text[-1]\n",
    "\n",
    "#             text = ''.join(text)\n",
    "#             Predict_Next_Words(model, tokenizer, text)\n",
    "            \n",
    "#         except:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the Libraries\n",
    "# from tensorflow.keras.models import load_model\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# model = load_model('nextword1.h5')\n",
    "# tokenizer = pickle.load(open('tokenizer1.pkl', 'rb'))\n",
    "\n",
    "# def Predict_Next_Words(model, tokenizer, text):\n",
    "#     \"\"\"\n",
    "#     This function uses the trained tokenizer and model to create a sequence of the input text\n",
    "#     and predict the next word in the sequence.\n",
    "#     \"\"\"\n",
    "#     sequence = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "#     if not sequence or len(sequence[0]) == 0:\n",
    "#         print(\"The provided word is not in the tokenizer's vocabulary.\")\n",
    "#         return \"\"\n",
    "    \n",
    "#     sequence = np.array(sequence[0]).reshape(1, -1)\n",
    "    \n",
    "#     preds = model.predict(sequence)\n",
    "#     predicted_word_index = np.argmax(preds, axis=1)[0]\n",
    "    \n",
    "#     predicted_word = \"\"\n",
    "#     for word, index in tokenizer.word_index.items():\n",
    "#         if index == predicted_word_index:\n",
    "#             predicted_word = word\n",
    "#             break\n",
    "    \n",
    "#     return predicted_word\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('nextword1.h5')\n",
    "tokenizer = pickle.load(open('tokenizer1.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    This function uses the trained tokenizer and model to create a sequence of the input text\n",
    "    and predict the next word in the sequence.\n",
    "    \"\"\"\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "    if not sequence or len(sequence[0]) == 0:\n",
    "        print(\"The provided word is not in the tokenizer's vocabulary.\")\n",
    "        return \"\"\n",
    "    \n",
    "    sequence = np.array(sequence[0]).reshape(1, -1)\n",
    "    \n",
    "    preds = model.predict(sequence)\n",
    "    predicted_word_index = np.argmax(preds, axis=1)[0]\n",
    "    \n",
    "    predicted_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            predicted_word = word\n",
    "            break\n",
    "    \n",
    "    return predicted_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "Predicted next word: weather\n",
      "The provided word is not in the tokenizer's vocabulary.\n",
      "No prediction could be made.\n",
      "The provided word is not in the tokenizer's vocabulary.\n",
      "No prediction could be made.\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Predicted next word: weather\n",
      "Ending The Program.....\n"
     ]
    }
   ],
   "source": [
    "# text1 = \"at the dull\"\n",
    "# text2 = \"collection of textile\"\n",
    "# text3 = \"what a strenuous\"\n",
    "# text4 = \"stop the script\"\n",
    "# while True:\n",
    "    \n",
    "#     text =input(\"Enter the line :\")\n",
    "    \n",
    "#     if text.lower() == \"stop the script\":\n",
    "#         print(\"Ending The Program.....\")\n",
    "#         break\n",
    "    \n",
    "#     else:\n",
    "#         try:\n",
    "#             # Get the last word for prediction\n",
    "#             text= text.split()\n",
    "#             last_word=text[-1]\n",
    "#             print(f\"Last word to predict next word for: {last_word}\")\n",
    "            \n",
    "#             # Predict the next word\n",
    "#             predicted_word = Predict_Next_Words(model, tokenizer, last_word)\n",
    "            \n",
    "#             if predicted_word:\n",
    "#                 # Print the predicted word\n",
    "#                 print(\"Predicted next word:\", predicted_word)\n",
    "#             else:\n",
    "#                 print(\"No prediction could be made.\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(\"Error occurred:\", e)\n",
    "#             continue\n",
    "while True:\n",
    "    text = input(\"Enter the line: \")\n",
    "    \n",
    "    if text.lower() == \"stop the script\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        text = text.split(\" \")\n",
    "        text_1 = text[-1]\n",
    "        # Predict the next word based on the entire input text\n",
    "        predicted_word = Predict_Next_Words(model, tokenizer, text_1)\n",
    "        \n",
    "        if predicted_word:\n",
    "            # Print the predicted word\n",
    "            print(\"Predicted next word:\", predicted_word)\n",
    "        else:\n",
    "            print(\"No prediction could be made.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
